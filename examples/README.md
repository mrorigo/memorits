# Memori TypeScript Examples

This directory contains comprehensive examples demonstrating how to use the Memori TypeScript library for memory-enabled conversations with multiple AI providers including OpenAI, Ollama, and Anthropic.

## Prerequisites

1. **Node.js** (version 16 or higher)
2. **npm** or **yarn** package manager
3. **Database**: SQLite (default) or PostgreSQL/MySQL
4. **AI Backend**: Either OpenAI API or Ollama

## Simple Setup

The examples use a simple configuration approach:

```typescript
import { Memori, OpenAIWrapper } from 'memorits';

// Simple configuration
const memori = new Memori({
  databaseUrl: 'file:./memories.db',
  namespace: 'my-app',
  apiKey: 'your-api-key',
  autoMemory: true
});

// Provider wrapper with direct integration
const openai = new OpenAIWrapper(memori);
```

### Setting up OpenAI

1. Get your API key from [OpenAI Platform](https://platform.openai.com/api-keys)
2. Use it directly in your code:
   ```typescript
   const memori = new Memori({
     databaseUrl: 'file:./memories.db',
     namespace: 'my-app',
     apiKey: 'your-openai-api-key',
     autoMemory: true
   });
   ```

### Setting up Ollama

1. Install Ollama from [ollama.ai](https://ollama.ai)
2. Start the Ollama server:
   ```bash
   ollama serve
   ```
3. Pull a model:
   ```bash
   ollama pull llama2
   ollama pull codellama
   ```
4. Use it in your code:
   ```typescript
   const memori = new Memori({
     databaseUrl: 'file:./memories.db',
     namespace: 'my-app',
     apiKey: 'ollama-local',
     baseUrl: 'http://localhost:11434',
     autoMemory: true
   });
   ```

## Running Examples

### Using npm Scripts

The examples can be run using the following npm scripts:

```bash
# Basic usage example
npm run example:basic

# Unified usage example
npm run example:unified

# Multi-provider usage demonstration
npm run example:multi-provider
```

### Running Individual Examples Directly

You can also run examples directly with tsx:

```bash
# Basic usage
npx tsx examples/basic-usage.ts

# Unified usage (recommended)
npx tsx examples/unified-usage.ts

# Multi-provider usage
npx tsx examples/multi-provider-usage.ts
```

## Example Descriptions

### 1. Basic Usage (`basic-usage.ts`)

Demonstrates fundamental Memori operations:
- Initializing Memori with environment configuration
- Recording conversations
- Searching and retrieving memories
- Proper cleanup and error handling

**Expected Output:**
- Configuration loading confirmation
- Conversation recording with IDs
- Memory search results for "TypeScript" and "interfaces"
- Successful cleanup confirmation

### 2. Ollama Integration (`ollama-integration.ts`)

Shows how to configure and use Memori with Ollama:
- Ollama-specific configuration validation
- Local LLM conversation recording
- Memory processing with local models
- Error handling for common Ollama issues

**Expected Output:**
- Ollama configuration validation
- Multiple conversation recordings with metadata
- Memory searches for "local LLM", "efficient", and "programming"
- Troubleshooting suggestions if Ollama is not available

### 3. OpenAI Integration (`openai-integration.ts`)

Demonstrates OpenAI API integration:
- OpenAI API key validation
- GPT model conversation recording
- Memory processing with OpenAI models
- Rate limiting and error handling

**Expected Output:**
- OpenAI configuration validation
- API key verification
- Conversation recordings with programming concepts
- Memory searches for "JavaScript", "async", and "React"
- API usage guidance

### 4. Memory Search (`memory-search.ts`)

Advanced memory search and retrieval demonstration:
- Building a diverse memory base
- Various search query types
- Cross-topic memory relationships
- Category-based memory organization

**Expected Output:**
- Comprehensive memory database creation
- Multiple search demonstrations across different topics
- Category analysis and memory relationships
- Semantic search capabilities showcase

### 5. Dual Memory Mode (`dual-memory-mode.ts`)

Comprehensive demonstration of Memori's dual memory processing modes:
- **Auto-ingestion mode**: Automatic conversation processing into memories
- **Conscious ingestion mode**: Manual processing with background monitoring
- **Mode status checking**: Query current processing state
- **Background processing**: Configurable monitoring intervals
- **Relationship extraction control**: Independent control of relationship processing

**Expected Output:**
- Auto-ingestion mode demonstration with automatic memory processing
- Conscious ingestion mode with manual processing triggers
- Background monitoring configuration and status
- Mode status verification and comparison
- Relationship extraction control examples (enabled/disabled scenarios)

### 6. Performance Dashboard (`performance-dashboard.ts`)

Comprehensive demonstration of Memori's performance monitoring and alerting capabilities:
- **Dashboard initialization**: Setting up default widgets and real-time collection
- **System status monitoring**: Overall health and component-specific metrics
- **Real-time metrics**: Collection and analysis of performance data
- **Alert management**: Threshold-based alerting and acknowledgment system
- **Performance reporting**: Detailed analysis and trend identification
- **Widget management**: Dynamic dashboard configuration and updates

**Expected Output:**
- Dashboard service initialization with default widgets
- Real-time system status overview with component health
- Live metrics collection and alert generation
- Performance report generation with trends and recommendations
- Alert acknowledgment and resolution workflow
- Dashboard configuration export and management

### 7. Memory Consolidation (`memory-consolidation.ts`)

Demonstrates the memory consolidation service:
- **Duplicate detection**: Using similarity algorithms to find duplicate memories
- **Memory consolidation**: Safe merging with rollback capabilities
- **Architecture overview**: Clean service-oriented design for maintainability
- **Performance characteristics**: Fast duplicate detection and processing
- **Service integration**: How consolidation works with existing Memori features

**Expected Output:**
- Memory creation for consolidation demonstration
- Duplicate detection results with similarity analysis
- Consolidation process with rollback safety
- Architecture capabilities demonstration
- Performance metrics and system capabilities
- Service design and integration showcase

### 8. Multi-Provider Usage (`multi-provider-usage.ts`) **[NEW]**

Comprehensive demonstration of Memori's multi-provider architecture:
- **Provider capabilities**: Show available provider types and configurations
- **Multi-provider memory**: Use multiple providers simultaneously with separate namespaces
- **Provider switching**: Demonstrate seamless switching between different providers
- **Factory pattern usage**: Show how to use the provider factory for dynamic provider creation
- **Cross-provider memory search**: Search memories across different provider namespaces

**Key Features Demonstrated:**
- **Provider Factory**: Automatic provider registration and creation
- **Multi-Provider Setup**: Running multiple Memori instances with different providers
- **Namespace Isolation**: Separate memory spaces for different providers
- **Provider Detection**: Automatic provider type detection from configuration
- **Memory Continuity**: Maintaining memory access across provider switches

**Expected Output:**
- Provider capabilities overview and registration status
- Multi-provider initialization with separate namespaces
- Cross-provider conversation recording and memory processing
- Memory search across different provider namespaces
- Provider switching demonstration with maintained memory access
- Best practices for multi-provider applications

**Use Cases:**
- Applications requiring multiple AI providers for different tasks
- Development environments with both local (Ollama) and cloud (OpenAI) models
- A/B testing different providers for performance comparison
- Failover scenarios with provider backup strategies

## Expected Output Examples

### Basic Usage Example Output
```
üöÄ Starting Basic Memori Usage Example...

üìã Configuration loaded: {
  databaseUrl: 'file:./memori.db',
  namespace: 'development',
  model: 'gpt-4o-mini',
  baseUrl: 'http://localhost:11434/v1'
}

‚úÖ Memori instance created
‚úÖ Memori enabled successfully

üí¨ Recording conversation...
‚úÖ Conversation recorded with ID: abc-123-def

üîç Searching memories for "TypeScript"...
‚úÖ Found 3 relevant memories:
1. TypeScript is a superset of JavaScript...
2. Variables can be declared with type annotations...
3. Interfaces define object structures...

üéâ Basic usage example completed successfully!
```

### Ollama Integration Example Output
```
üöÄ Starting Ollama Integration Example...

üìã Ollama Configuration: {
  databaseUrl: 'file:./memori.db',
  namespace: 'development',
  model: 'llama2',
  baseUrl: 'http://localhost:11434/v1'
}

‚úÖ Memori instance created with Ollama backend
‚úÖ Memori enabled successfully

üí¨ Recording conversations with Ollama context...
‚úÖ Conversation 1 recorded: def-456-ghi
‚úÖ Conversation 2 recorded: ghi-789-jkl

üîç Searching memories for "local LLM"...
‚úÖ Found 2 memories about local LLMs:
1. Local LLMs provide privacy and control...
2. You can run models efficiently on local hardware...

üéâ Ollama integration example completed successfully!
```

### Performance Dashboard Example Output
```
üöÄ Starting Performance Dashboard Example

‚úÖ Performance dashboard service initialized
‚úÖ Dashboard initialized with default widgets
‚úÖ Alert callback registered

üìä Getting system status overview...
System Status Overview: healthy, 0 active alerts, 0 recent incidents

üéõÔ∏è Getting dashboard widgets...
Found 5 dashboard widgets:
Widget: System Overview (status_indicator)
Widget: Search Performance (metric_chart)
Widget: Database Metrics (metric_chart)
Widget: Active Alerts (alert_list)
Widget: Performance Trends (trend_analysis)

üìà Collecting real-time metrics...
Search latency metrics: 10 samples
Database latency metrics: 10 samples
System error rate metrics: 10 samples

üì∏ Getting performance snapshots...
Retrieved 3 performance snapshots

üìä Generating performance report...
Performance Report Generated: daily report with healthy status

üìà Analyzing performance trends...
Updated trend analysis for widgets

Alert Summary by Severity: 0 critical, 0 error, 0 warning

üíæ Exporting dashboard configuration...
Dashboard configuration exported: 5 widgets configured

üéâ Performance dashboard example completed successfully!
```

## Troubleshooting

### Common Issues

#### 1. Database Connection Errors
- Ensure `DATABASE_URL` is properly set in `.env`
- For SQLite: use `file:./memori.db` (default)
- For PostgreSQL: use `postgresql://user:password@localhost:5432/memori`

#### 2. OpenAI API Errors
- Verify `OPENAI_API_KEY` is set and valid
- Check your OpenAI account has sufficient credits
- Ensure you're not hitting rate limits

#### 3. Ollama Connection Errors
- Make sure Ollama is installed and running
- Check if the service is on port 11434
- Verify the model is downloaded: `ollama pull llama2`

#### 4. Memory Processing Issues
- Ensure memory processing is enabled in configuration
- Check that conversations are being recorded properly
- Wait for asynchronous memory processing to complete

### Debug Mode

To enable verbose logging, set the following in your `.env`:
```env
DEBUG=memori:*
```

### Getting Help

If you encounter issues:

1. Check the error messages in the console output
2. Verify your environment configuration
3. Ensure all prerequisites are installed
4. Try running the basic example first to isolate issues
5. Check the [Memori documentation](../README.md) for more details

## Provider Architecture

### Current Architecture Overview

The Memori library now supports a modern provider architecture that enables:

1. **Multiple Provider Support**: OpenAI, Ollama, and Anthropic providers
2. **Factory Pattern**: Centralized provider creation and management
3. **Automatic Provider Detection**: Configuration-based provider selection
4. **Backward Compatibility**: Existing code continues to work unchanged

### Provider Configuration

#### OpenAI Provider
```env
OPENAI_API_KEY="sk-your-openai-key"
MEMORI_MODEL="gpt-4o-mini"
# OPENAI_BASE_URL not needed for OpenAI
```

#### Ollama Provider
```env
OPENAI_API_KEY="ollama-local"
OPENAI_BASE_URL="http://localhost:11434/v1"
MEMORI_MODEL="llama2"
```

#### Anthropic Provider
```env
OPENAI_API_KEY="sk-ant-api03-your-anthropic-key"
OPENAI_BASE_URL="https://api.anthropic.com"
MEMORI_MODEL="claude-3-sonnet-20240229"
```

### Best Practices

1. **Provider Registration**: The Memori class automatically registers all available providers
2. **Configuration Validation**: Always validate your provider configuration before use
3. **Error Handling**: Implement proper error handling for provider-specific issues
4. **Resource Cleanup**: Always call `await memori.close()` to clean up resources
5. **Namespace Management**: Use different namespaces for different providers or use cases

### Migration from Legacy Code

If you're updating from older versions:

1. **No API changes required**: Existing `Memori` class usage continues to work
2. **Automatic provider detection**: The library detects the provider from your configuration
3. **Enhanced error messages**: Better error reporting for provider issues
4. **Improved performance**: Optimized provider loading and caching

## Advanced Configuration

For production use, consider these additional settings:

```env
# Production database
DATABASE_URL="postgresql://user:password@prod-host:5432/memori"

# Production namespace
MEMORI_NAMESPACE="production"

# Enable memory features
MEMORI_CONSCIOUS_INGEST="true"
MEMORI_AUTO_INGEST="true"

# User context for better memory processing
MEMORI_USER_CONTEXT='{
  "userPreferences": ["TypeScript", "React", "Node.js"],
  "currentProjects": ["web-app", "api-service"],
  "relevantSkills": ["fullstack", "devops", "ai"]
}'
```

## Next Steps

After running these examples:

1. **Experiment** with different conversation topics
2. **Customize** the memory search queries
3. **Integrate** Memori into your own applications
4. **Explore** advanced configuration options
5. **Contribute** your own examples to the project

For more information, see the main [README](../README.md) and explore the source code in the `src/` directory.